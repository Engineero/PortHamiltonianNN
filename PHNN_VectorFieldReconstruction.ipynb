{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torchdiffeq import odeint\n",
    "from torchcontrol.arch_cpugpu import HDNN, HDNN_Observer\n",
    "from torchcontrol.utils import genpoints\n",
    "import scipy\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import LSTM\n",
    "from matplotlib2tikz import save as tikz_save\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duffin Oscillator\n",
    "\n",
    "$$\\begin{bmatrix}\\dot{u}\\\\\\dot{v}\\end{bmatrix}= \\begin{bmatrix}v\\\\-\\alpha u - k v -\\beta u^3\\end{bmatrix}$$\n",
    "$$\\Leftrightarrow\\dot{x}= \\Psi(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0\n",
    "b = 1\n",
    "c = 1.0\n",
    "d = 1\n",
    "# Dissipation rate\n",
    "k = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ODE\n",
    "def LV(x,t):\n",
    "    u = x[0]\n",
    "    v = x[1]\n",
    "    dudt = v#a*u - b*u*v #\n",
    "    dvdt = -a*u - k*v -b*pow(u,3) #-c*v +d*u*v + k*(a-b*v)*v#\n",
    "    return [dudt,dvdt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the systems\n",
    "N = 200\n",
    "Tf = 4\n",
    "Ts = Tf/N\n",
    "print('The sampling time is ',Ts,'s')\n",
    "t = np.linspace(0,Tf,N)\n",
    "# standard form\n",
    "x0 = [1.5,1]\n",
    "x = odeint(LV,x0,t)\n",
    "x1 = odeint(LV,x[-1],t)\n",
    "t = np.hstack((t,t+t[-1]))\n",
    "x = np.vstack((x,x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save traj\n",
    "orig_traj = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Np = 20\n",
    "xlim = np.hstack((orig_traj.min(0)[0],orig_traj.max(0)[0]))\n",
    "ylim = np.hstack((orig_traj.min(0)[1],orig_traj.max(0)[1]))\n",
    "\n",
    "x1 = np.linspace(xlim[0],xlim[1],Np)\n",
    "x2 = np.linspace(ylim[0],ylim[1],Np)\n",
    "X1,X2 = np.meshgrid(x1,x2)\n",
    "\n",
    "U = np.zeros((Np,Np))\n",
    "V = np.zeros((Np,Np))\n",
    "\n",
    "for i in range(Np):\n",
    "    for j in range(Np):\n",
    "        U[i,j], V[i,j] = LV([X1[i,j],X2[i,j]],0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X1, X2, U, V,scale = 80)\n",
    "ax.plot(x[:,0],x[:,1])\n",
    "ax.scatter(x[:,0],x[:,1], color = 'r')\n",
    "plt.xlim([xlim[0],xlim[1]])\n",
    "plt.ylim([ylim[0],ylim[1]])\n",
    "\n",
    "\n",
    "X1a = X1.reshape(int(Np*Np),1)\n",
    "X2a = X2.reshape(int(Np*Np),1)\n",
    "Ua = U.reshape(int(Np*Np),1)\n",
    "Va = V.reshape(int(Np*Np),1)\n",
    "\n",
    "VecField = np.hstack((X1a,np.hstack((X2a,np.hstack((Ua,Va))))))\n",
    "np.savetxt('VecField.dat', VecField, fmt=['%.3f','%.3f','%.3f','%.3f'],delimiter='\\t',header=\"x\\ty\\tu\\tv\",comments = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x[:,0],x[:,1])\n",
    "ax.scatter(x[:,0],x[:,1], color = 'r')\n",
    "plt.xlim([xlim[0],xlim[1]])\n",
    "plt.ylim([ylim[0],ylim[1]])\n",
    "tikz_save('Traj.tex')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods attempted: 1st - approximation of derivative with $$\\hat{y}_i = \\frac{(\\hat{u}_{i+1} - \\hat{u}_{i})}{Ts}$$\n",
    "2nd - use as labels $$LV(x_{i}, t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(x).to(device)\n",
    "x[1:]\n",
    "x0 = x[0].view(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with approx\n",
    "grad = ([(x[i+1] - x[i])/Ts for i in range(len(x)-1)])\n",
    "grad = torch.Tensor([g.cpu().numpy() for g in grad])\n",
    "# with real LV\n",
    "#grad = ([LV(x[i], t) for i in range(len(x)-1)])\n",
    "#grad = torch.Tensor([g for g in grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(x[:-1], grad)\n",
    "trainloader = data_utils.DataLoader(train, batch_size=len(orig_traj)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural Network\n",
    "obs = HDNN('MLP', [[2, 16, 16, 2], False], [1,1,0], 0.5, odeint='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1t = torch.Tensor(X1).to(device)\n",
    "X2t = torch.Tensor(X2).to(device)\n",
    "Up = np.zeros((Np,Np))\n",
    "Vp = np.zeros((Np,Np))\n",
    "\n",
    "for i in range(Np):\n",
    "    for j in range(Np):\n",
    "        point = torch.Tensor([X1[i,j],X2[i,j]]).to(device)\n",
    "        Up[i,j], Vp[i,j] = obs.predictor(point.view(1,2))[0][0],obs.predictor(point.view(1,2))[0][1]\n",
    "\n",
    "Uo, Vo = Up, Vp\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X1, X2, Up, Vp,scale = 80)\n",
    "plt.title(\"Pre training approximated vector field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200000\n",
    "ode_t = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "obs.fit(trainloader, epoch=200000, time_delta=100, iter_accuracy=float('inf'), ode_t=0.001, ode_step=2, criterion='mse')\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss function\n",
    "#obs.plotLoss()\n",
    "J = ([np.array(obs.pLoss[i].to('cpu').detach().numpy(),dtype='float').tolist() for i in range(len(obs.pLoss))])\n",
    "\n",
    "T = np.linspace(0,epoch*ode_t,len(J))\n",
    "plt.figure()\n",
    "plt.plot(T[0:-1:10],J[0:-1:10])\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$\\mathcal{J}^*(t)$\")\n",
    "plt.xlim([0,30])\n",
    "\n",
    "plt.savefig('LossVF.eps', format='eps', dpi=300)\n",
    "tikz_save('LossVF.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(obs.pWdot)\n",
    "theta = np.zeros((len(J),p))\n",
    "omega = np.zeros((len(J),p))\n",
    "for j in range(p):\n",
    "    theta[:,j] = ([obs.pW[j][i].tolist() for i in range(len(J))])\n",
    "    omega[:,j] = ([obs.pWdot[j][i].tolist() for i in range(len(J))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import rc\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "# ## for Palatino and other serif fonts use:\n",
    "# #rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# rc('text', usetex=True)\n",
    "colors = plt.cm.jet(np.linspace(0,1,len(theta)))\n",
    "plt.figure(figsize=(7,12))\n",
    "plt.subplot(311);\n",
    "skip = 20\n",
    "#for i in range(p-300):\n",
    "#    plt.plot(T, theta[:,i], color=colors[i])\n",
    "plt.plot(T[0:-1:skip],theta[0:-1:skip], Linewidth = 3, alpha = 1);\n",
    "#plt.plot(T,theta[:,0:47],Linewidth = 3, color = 'b',alpha = 0.5);\n",
    "#plt.plot(T,theta[:,48:48+272],Linewidth = 3, color = 'r',alpha = 0.5);\n",
    "#plt.plot(T,theta[:,48+273:-1],Linewidth = 3, color = 'g',alpha = 0.5);\n",
    "#plt.xlabel(\"$t$\");\n",
    "plt.ylabel(\"$\\theta$\");\n",
    "plt.xlim([0,30])\n",
    "plt.subplot(312);\n",
    "plt.plot(T[0:-1:skip],omega[0:-1:skip],Linewidth = 3);\n",
    "#plt.xlabel(\"$t$\");\n",
    "plt.ylabel(\"$\\omega(t)$\");\n",
    "plt.xlim([0,30])\n",
    "plt.subplot(313);\n",
    "plt.plot(T[0:-1:skip],J[0:-1:skip],Linewidth = 3);\n",
    "#plt.xlabel(\"$t$\");\n",
    "plt.ylabel(\"$\\mathcal{J}^*(t)$\")\n",
    "plt.xlim([0,30])\n",
    "#plt.savefig('weightsVF.eps', format='eps', dpi=300);\n",
    "tikz_save('weightsVF.tex');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute reconstructed vector field & reconstruction error\n",
    "\n",
    "given the linear system:\n",
    "\\begin{equation}\n",
    "    \\dot{x} = \\Psi(x)\n",
    "\\end{equation}\n",
    "Let the neural network model be\n",
    "\\begin{equation}\n",
    "    y = f(x,\\vartheta)\n",
    "\\end{equation}\n",
    "After the training, the reconstruction error is computed (in a certain quantized region of the state-space) as\n",
    "\\begin{equation}\n",
    "    E(x) = \\|\\Psi(x)-f(x,\\vartheta^*)\\|_2^2\n",
    "\\end{equation}\n",
    "where $\\vartheta^*$ is the trained vector of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Up = np.zeros((Np,Np))\n",
    "Vp = np.zeros((Np,Np))\n",
    "\n",
    "for i in range(int(Np)):\n",
    "    for j in range(Np):\n",
    "        point = torch.Tensor([X1[i,j],X2[i,j]]).to(device)\n",
    "        Up[i,j], Vp[i,j] = obs.predictor(point.view(1,2))[0][0], obs.predictor(point.view(1,2))[0][1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "q = ax.quiver(X1, X2, U, V,scale = 80)\n",
    "q = ax.quiver(X1, X2, Up, Vp, scale = 80,color = 'r')\n",
    "plt.title(\"Learned vec field vs ground truth\")\n",
    "\n",
    "Upa = Up.reshape(int(Np*Np),1)\n",
    "Vpa = Vp.reshape(int(Np*Np),1)\n",
    "\n",
    "RecVecField = np.hstack((X1a,np.hstack((X2a,np.hstack((Upa,Vpa))))))\n",
    "np.savetxt('RecVecField.dat', RecVecField, fmt=['%.3f','%.3f','%.3f','%.3f'],delimiter='\\t',header=\"x\\ty\\tu\\tv\",comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error contour plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.zeros((Np,Np))\n",
    "\n",
    "for i in range(Np):\n",
    "    for j in range(Np):\n",
    "        E[i,j] = np.sqrt(pow(U[i,j]-Up[i,j],2)+pow(V[i,j]-Vp[i,j],2))#/np.sqrt(pow(U[i,j],2)+pow(V[i,j],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Plot contour map of the vector field's reconstruction error\n",
    "#plt.figure(figsize=(12,8))\n",
    "plt.contourf(X1, X2, E,100,cmap='Blues')\n",
    "plt.plot(orig_traj[:,0],orig_traj[:,1], color='black')\n",
    "plt.colorbar()\n",
    "plt.title(\"Vector Field reconstruction Error\")\n",
    "\n",
    "Ea = E.reshape(int(Np*Np),1)\n",
    "\n",
    "Error = np.hstack((X1a,np.hstack((X2a,Ea))))\n",
    "np.savetxt('Error.dat', Error, fmt=['%.3f','%.3f','%.3f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructed trajectory\n",
    "\n",
    "We want to compare the reference trajectory $x_{r}(t)$ obtained by integrating the ODE $\\dot{x}=\\Psi(x)$ with $x_r(0) = x_0$ with a trajectory $\\hat{x}(t)$ obtained by integrating $\\dot{x}= f(x,\\theta^*)$ (the NN model) with the same initial condition.\n",
    "\n",
    "We can then evaluate how the reconstructed trajectory remains close to $x_r(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LV_Learned(xi0, t):\n",
    "    return obs.predictor(torch.Tensor(xi0).view(1,2).to(device)).flatten().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = LV_Learned\n",
    "t = np.linspace(0,2*Tf,2*N)\n",
    "x0 = [1.5, 1]\n",
    "sol = odeint(func, x0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot([s[0] for s in sol], [s[1] for s in sol])\n",
    "plt.plot(orig_traj[:,0],orig_traj[:,1], color='black')\n",
    "plt.legend(['Learned','Original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ([np.linalg.norm(sol[i]-orig_traj[i]) for i in range(len(orig_traj))])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
